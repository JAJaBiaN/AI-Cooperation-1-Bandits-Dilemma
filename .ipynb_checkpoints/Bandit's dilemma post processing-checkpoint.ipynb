{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_array_data(path, num_runs=20, window_over=5, step=3, plot_results=False):\n",
    "    \"\"\"Loop through a collection of experiments,\n",
    "    plotting the choices of the two bandits and using windowing to smooth out their reward data\"\"\"\n",
    "    \n",
    "    # Make sure that the string specifying the path works with the rest of the code\n",
    "    print(path)\n",
    "    if path[-1] != \"/\":\n",
    "        path = path+\"/\"\n",
    "    \n",
    "    # Loop through experiments in this path\n",
    "    for file in os.listdir(path):\n",
    "        df = pd.read_csv(path+file+\"/array data.csv\", index_col=0)\n",
    "        print(\"\\n\\n____\"+str(file)+\"____\")\n",
    "        for run in range(num_runs):\n",
    "            if plot_results:\n",
    "                # Plot and save the choices made by bandit 0 during this run and save it into the experiment folder\n",
    "                plt.figure()\n",
    "                plt.plot(df[\"Run \"+str(run)+\", Choices 0\"])\n",
    "                plt.title(str(file)+\" Choices for Bandit 0\")\n",
    "                plt.ylabel(\"Choice: 0=stay silent, 1=betray\")\n",
    "                plt.xlabel(\"Time step\")\n",
    "                plt.savefig(str(path+file)+\"/Run \"+str(run)+\"Choices for Bandit 0.png\")\n",
    "                plt.show()\n",
    "\n",
    "                # Plot and save the choices made by bandit 1 during this run and save it into the experiment folder\n",
    "                plt.figure()\n",
    "                plt.plot(df[\"Run \"+str(run)+\", Choices 1\"])\n",
    "                plt.title(str(file)+\" Choices for Bandit 1\")\n",
    "                plt.ylabel(\"Choice: 0=stay silent, 1=betray\")\n",
    "                plt.xlabel(\"Time step\")\n",
    "                plt.savefig(str(path+file)+\"/Run \"+str(run)+\"Choices for Bandit 1.png\")\n",
    "                plt.show()\n",
    "\n",
    "            # Average the rewards over windows to smooth out the data and hopefully make patterns easier to see\n",
    "            rewards0 = df[\"Run \"+str(run)+\", Rewards 0\"]\n",
    "            rewards1 = df[\"Run \"+str(run)+\", Rewards 1\"]\n",
    "            windowed_r0 = []\n",
    "            windowed_r1 = []\n",
    "            for t in range(0,len(rewards0)-window_over,step):\n",
    "                windowed_r0.append(np.sum(rewards0[t:t+window_over])/window_over)\n",
    "                windowed_r1.append(np.sum(rewards1[t:t+window_over])/window_over)\n",
    "\n",
    "            # Save the windowed rewards information for later referral\n",
    "            if run == 0:\n",
    "                window_frame = pd.DataFrame({\"Run 0, Windowed Rewards 0\":windowed_r0, \"Run 0, Windowed Rewards 1\":windowed_r1})\n",
    "            else:\n",
    "                window_frame[\"Run \"+str(run)+\", Windowed Rewards 0\"] = windowed_r0\n",
    "                window_frame[\"Run \"+str(run)+\", Windowed Rewards 1\"] = windowed_r1\n",
    "            window_frame.to_csv(str(path+file)+\"/Windowed reward data, window size=\"+str(window_over)+\", step=\"+str(step)+\".csv\")\n",
    "        \n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_cumulative_rewards(path, num_runs=20):\n",
    "    \"\"\"Loop through a collection of experiments,\n",
    "    plotting the choices of the two bandits and using windowing to smooth out their reward data\"\"\"\n",
    "    \n",
    "    # Make sure that the string specifying the path works with the rest of the code\n",
    "    if path[-1] != \"/\":\n",
    "        path = path+\"/\"\n",
    "    \n",
    "    # Loop through experiments in this path\n",
    "    for file in os.listdir(path):\n",
    "        df = pd.read_csv(path+file+\"/array data.csv\", index_col=0)\n",
    "        print(\"\\n____\"+str(file)+\"____\")\n",
    "        \n",
    "        # Loop through runs, gathering cumulative reward data\n",
    "        avg_cumulative_reward_0 = 0\n",
    "        avg_cumulative_reward_1 = 0\n",
    "        for run in range(num_runs):\n",
    "            avg_cumulative_reward_0 += np.sum(df[\"Run \"+str(run)+\", Rewards 0\"])\n",
    "            avg_cumulative_reward_1 += np.sum(df[\"Run \"+str(run)+\", Rewards 1\"])\n",
    "        avg_cumulative_reward_0 /= float(num_runs)\n",
    "        avg_cumulative_reward_1 /= float(num_runs)\n",
    "        \n",
    "        print(\"Average cumulative reward for\", file)\n",
    "        print(\"\\tBandit 0:\", avg_cumulative_reward_0)\n",
    "        print(\"\\tBandit 1:\", avg_cumulative_reward_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected reward in Nash equilibrium (double betrayal): -400\n",
      "Expected reward if learner always betrays but random is exactly 50:50: -200.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected reward in Nash equilibrium (double betrayal):\", -2*200)\n",
    "print(\"Expected reward if learner always betrays but random is exactly 50:50:\", 200*(0-2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that most of the time both learning bandits chose to betray with little variation for choice of hyperparameter. Given the simplicity of the set up, both learners shouldn't need a lot of exploration to learn the optimal long-term strategy. This is why both learners performed best when their hyperparameters were so small.\n",
    "\n",
    "However, in order to exhibit cooperative behaviour, I expect that the learners will need to be slightly more willing to explore. That is why I have set the value of e to be 0.15 for the eGreedy bandit and the value of c to be 1 for the UCB bandit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_betrayal_proportion(path, num_runs=20):\n",
    "    \"\"\"Get the proportion of time that both bandits in an experiment betrayed the other bandit\"\"\"\n",
    "    \n",
    "    # Make sure that the string specifying the path works with the rest of the code\n",
    "    if path[-1] != \"/\":\n",
    "        path = path+\"/\"\n",
    "    \n",
    "    # Loop through experiments in this path\n",
    "    for file in os.listdir(path):\n",
    "        # Read in data\n",
    "        df = pd.read_csv(path+file+\"/array data.csv\", index_col=0)\n",
    "        print(file)\n",
    "\n",
    "        avg_betrayal_proportion_0 = 0\n",
    "        avg_betrayal_proportion_1 = 0\n",
    "        # Gather the data\n",
    "        for run in range(num_runs):\n",
    "            avg_betrayal_proportion_0 += np.sum(df[\"Run \"+str(run)+\", Choices 0\"])\n",
    "            avg_betrayal_proportion_1 += np.sum(df[\"Run \"+str(run)+\", Choices 1\"])\n",
    "\n",
    "        avg_betrayal_proportion_0 /= len(df[\"Run 0, Choices 0\"])*num_runs\n",
    "        avg_betrayal_proportion_1 /= len(df[\"Run 0, Choices 0\"])*num_runs\n",
    "    \n",
    "        print(avg_betrayal_proportion_0, avg_betrayal_proportion_1)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_array_data(\"./Round Robin experiments 100 Runs/\", num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg_cumulative_rewards(\"./Round Robin experiments 100 Runs/\", num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get betrayal proportion data for all matchups in the round robin\n",
    "get_avg_betrayal_proportion(\"./Round Robin experiments 100 Runs\", num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare betrayal proportions and average reward for all 7 types of bandit\n",
    "plt.plot([49.79625,62.7725,62.846875,74.30687])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./No-regret testing/\n",
      "\n",
      "\n",
      "____No-regret bandit vs eGreedy bandit e=0.15, T=200, 100 episodes____\n",
      "\n",
      "\n",
      "____No-regret bandit vs No-regret bandit, T=200, 100 episodes____\n",
      "\n",
      "\n",
      "____No-regret bandit vs Optimal bandit, T=200, 100 episodes____\n",
      "\n",
      "\n",
      "____No-regret bandit vs Random bandit, T=200, 100 episodes____\n",
      "\n",
      "\n",
      "____No-regret bandit vs Rational bandit, T=200, 100 episodes____\n",
      "\n",
      "\n",
      "____No-regret bandit vs UCB bandit c=1, T=200, 100 episodes____\n"
     ]
    }
   ],
   "source": [
    "process_array_data(\"./No-regret testing/\", num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____No-regret bandit vs eGreedy bandit e=0.15, T=200, 100 episodes____\n",
      "Average cumulative reward for No-regret bandit vs eGreedy bandit e=0.15, T=200, 100 episodes\n",
      "\tBandit 0: -364.94\n",
      "\tBandit 1: -407.39\n",
      "\n",
      "____No-regret bandit vs No-regret bandit, T=200, 100 episodes____\n",
      "Average cumulative reward for No-regret bandit vs No-regret bandit, T=200, 100 episodes\n",
      "\tBandit 0: -392.98\n",
      "\tBandit 1: -393.16\n",
      "\n",
      "____No-regret bandit vs Optimal bandit, T=200, 100 episodes____\n",
      "Average cumulative reward for No-regret bandit vs Optimal bandit, T=200, 100 episodes\n",
      "\tBandit 0: -402.85\n",
      "\tBandit 1: -388.69\n",
      "\n",
      "____No-regret bandit vs Random bandit, T=200, 100 episodes____\n",
      "Average cumulative reward for No-regret bandit vs Random bandit, T=200, 100 episodes\n",
      "\tBandit 0: -207.14\n",
      "\tBandit 1: -485.9\n",
      "\n",
      "____No-regret bandit vs Rational bandit, T=200, 100 episodes____\n",
      "Average cumulative reward for No-regret bandit vs Rational bandit, T=200, 100 episodes\n",
      "\tBandit 0: -406.42\n",
      "\tBandit 1: -387.16\n",
      "\n",
      "____No-regret bandit vs UCB bandit c=1, T=200, 100 episodes____\n",
      "Average cumulative reward for No-regret bandit vs UCB bandit c=1, T=200, 100 episodes\n",
      "\tBandit 0: -373.11\n",
      "\tBandit 1: -403.32\n"
     ]
    }
   ],
   "source": [
    "get_avg_cumulative_rewards(\"./No-regret testing/\", num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-regret bandit vs eGreedy bandit e=0.15, T=200, 100 episodes\n",
      "0.9662 0.89545\n",
      "\n",
      "No-regret bandit vs No-regret bandit, T=200, 100 episodes\n",
      "0.9655 0.9652\n",
      "\n",
      "No-regret bandit vs Optimal bandit, T=200, 100 episodes\n",
      "0.96705 0.99065\n",
      "\n",
      "No-regret bandit vs Random bandit, T=200, 100 episodes\n",
      "0.9649 0.5003\n",
      "\n",
      "No-regret bandit vs Rational bandit, T=200, 100 episodes\n",
      "0.9679 1.0\n",
      "\n",
      "No-regret bandit vs UCB bandit c=1, T=200, 100 episodes\n",
      "0.96625 0.9159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get betrayal proportion data for all matchups in the round robin\n",
    "get_avg_betrayal_proportion(\"./No-regret testing\", num_runs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Previous experimental runs for reference</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_list = [\"eGreedy\", \"UCB\"]\n",
    "\n",
    "for b0 in range(len(bandit_list)):\n",
    "    process_array_data(\"Hyperparameter tuning \"+bandit_list[b0]+\" 2, random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_list = [\"eGreedy\", \"UCB\"]\n",
    "\n",
    "for b0 in range(len(bandit_list)):\n",
    "    get_avg_cumulative_rewards(\"Hyperparameter tuning \"+bandit_list[b0]+\" 2, random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning against the optimal agent\n",
    "bandit_list = [\"eGreedy\", \"UCB\"]\n",
    "\n",
    "for b0 in range(len(bandit_list)):\n",
    "    process_array_data(\"Hyperparameter tuning \"+bandit_list[b0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through experiments and runs for the round robin\n",
    "path = \"./Round robin experiments/\"\n",
    "\n",
    "window_over = 5\n",
    "step = 3\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    df = pd.read_csv(path+file+\"/array data.csv\", index_col=0)\n",
    "    print(\"\\n\\n____\"+str(file)+\"____\")\n",
    "    for run in range(20):\n",
    "        # Plot and save the choices made by bandit 0 during this run and save it into the experiment folder\n",
    "        plt.figure()\n",
    "        plt.plot(df[\"Run \"+str(run)+\", Choices 0\"])\n",
    "        plt.title(str(file)+\" Choices for Bandit 0\")\n",
    "        plt.ylabel(\"Choice: 0=stay silent, 1=betray\")\n",
    "        plt.xlabel(\"Time step\")\n",
    "        plt.savefig(str(path+file)+\"/Run \"+str(run)+\"Choices for Bandit 0.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # Plot and save the choices made by bandit 1 during this run and save it into the experiment folder\n",
    "        plt.figure()\n",
    "        plt.plot(df[\"Run \"+str(run)+\", Choices 1\"])\n",
    "        plt.title(str(file)+\" Choices for Bandit 1\")\n",
    "        plt.ylabel(\"Choice: 0=stay silent, 1=betray\")\n",
    "        plt.xlabel(\"Time step\")\n",
    "        plt.savefig(str(path+file)+\"/Run \"+str(run)+\"Choices for Bandit 1.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # Average the rewards over windows to smooth out the data and hopefully make patterns easier to see\n",
    "        rewards0 = df[\"Run \"+str(run)+\", Rewards 0\"]\n",
    "        rewards1 = df[\"Run \"+str(run)+\", Rewards 1\"]\n",
    "        windowed_r0 = []\n",
    "        windowed_r1 = []\n",
    "        for t in range(0,len(rewards0)-window_over,step):\n",
    "            windowed_r0.append(np.sum(rewards0[t:t+window_over])/window_over)\n",
    "            windowed_r1.append(np.sum(rewards1[t:t+window_over])/window_over)\n",
    "\n",
    "        # Save the windowed rewards information for later referral\n",
    "        if run == 0:\n",
    "            window_frame = pd.DataFrame({\"Run 0, Windowed Rewards 0\":windowed_r0, \"Run 0, Windowed Rewards 1\":windowed_r1})\n",
    "        else:\n",
    "            window_frame[\"Run \"+str(run)+\", Windowed Rewards 0\"] = windowed_r0\n",
    "            window_frame[\"Run \"+str(run)+\", Windowed Rewards 1\"] = windowed_r1\n",
    "        window_frame.to_csv(str(path+file)+\"/Windowed reward data, window size=\"+str(window_over)+\", step=\"+str(step)+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
